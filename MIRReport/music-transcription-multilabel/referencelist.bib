
@inproceedings{ewert_dynamic_2015,
	title = {A dynamic programming variant of non-negative matrix deconvolution for the transcription of struck string instruments},
	doi = {10.1109/ICASSP.2015.7178033},
	abstract = {Given a musical audio recording, the goal of music transcription is to determine a score-like representation of the piece underlying the recording. Most current transcription methods employ variants of non-negative matrix factorization (NMF), which often fails to robustly model instruments producing non-stationary sounds. Using entire time-frequency patterns to represent sounds, non-negative matrix deconvolution (NMD) can capture certain types of non-stationary behavior but is only applicable if all sounds have the same length. In this paper, we present a novel method that combines the non-stationarity modeling capabilities available with NMD with the variable note lengths possible with NMF. Identifying frames in NMD patterns with states in a dynamical system, our method iteratively generates sound-object candidates separately for each pitch, which are then combined in a global optimization. We demonstrate the transcription capabilities of our method using piano pieces assuming the availability of single note recordings as training data.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Ewert, S. and Plumbley, M. D. and Sandler, M.},
	month = apr,
	year = {2015},
	keywords = {Acoustics, audio signal processing, Convolutive Signal Models, deconvolution, Dynamical Systems, dynamic programming, Hidden Markov models, Instruments, matrix decomposition, music, musical audio recording, Music Transcription, nonnegative matrix deconvolution, Non-Negative Matrix Deconvolution, nonnegative matrix factorization, nonstationarity modeling, score like representation, Signal processing, single note recordings, Speech, struck string instrument transcription, Time-frequency analysis, time frequency patterns, variable note lengths},
	pages = {569--573},
	file = {IEEE Xplore Abstract Record:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/TI3A46MG/7178033.html:text/html;IEEE Xplore Full Text PDF:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/65V6Q5RG/Ewert et al. - 2015 - A dynamic programming variant of non-negative matr.pdf:application/pdf}
}

@article{benetos_shift-invariant_2012,
	title = {A {Shift}-{Invariant} {Latent} {Variable} {Model} for {Automatic} {Music} {Transcription}},
	volume = {36},
	url = {http://openaccess.city.ac.uk/2427/},
	doi = {10.1162/COMJ_a_00146},
	abstract = {In this work, a probabilistic model for multiple-instrument automatic music transcription is proposed. The model extends the shift-invariant probabilistic latent component analysis method, which is used for spectrogram factorization. Proposed extensions support the use of multiple spectral templates per pitch and per instrument source, as well as a time-varying pitch contribution for each source. Thus, this method can effectively be used for multiple-instrument automatic transcription. In addition, the shift-invariant aspect of the method can be exploited for detecting tuning changes and frequency modulations, as well as for visualizing pitch content. For note tracking and smoothing, pitch-wise hidden Markov models are used. For training, pitch templates from eight orchestral instruments were extracted, covering their complete note range. The transcription system was tested on multiple-instrument polyphonic recordings from the RWC database, a Disklavier data set, and the MIREX 2007 multi-F0 data set. Results demonstrate that the proposed method outperforms leading approaches from the transcription literature, using several error metrics.},
	language = {en},
	number = {4},
	urldate = {2017-02-28},
	journal = {Computer Music Journal},
	author = {Benetos, E. and Dixon, S.},
	year = {2012},
	pages = {81--94},
	file = {Full Text PDF:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/BMD7H9WM/Benetos and Dixon - 2012 - A Shift-Invariant Latent Variable Model for Automa.pdf:application/pdf;Snapshot:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/K2H88DM4/2427.html:text/html}
}

@article{benetos_automatic_2013,
	title = {Automatic music transcription: challenges and future directions},
	issn = {0925-9902},
	shorttitle = {Automatic music transcription},
	url = {http://link.springer.com/journal/10844},
	doi = {10.1007/s10844-013-0258-3},
	abstract = {Automatic music transcription is considered by many to be a key enabling technology in music signal processing. However, the performance of transcription systems is still significantly below that of a human expert, and accuracies reported in recent years seem to have reached a limit, although the field is still very active. In this paper we analyse limitations of current methods and identify promising directions for future research. Current transcription methods use general purpose models which are unable to capture the rich diversity found in music signals. One way to overcome the limited performance of transcription systems is to tailor algorithms to specific use-cases. Semi-automatic approaches are another way of achieving a more reliable transcription. Also, the wealth of musical scores and corresponding audio data now available are a rich potential source of training data, via forced alignment of audio to scores, but large scale utilisation of such data has yet to be attempted. Other promising approaches include the integration of information from multiple algorithms and different musical aspects.},
	language = {en},
	number = {10.1007/s10844-013-0258-3},
	urldate = {2017-02-28},
	journal = {Journal of Intelligent Information Systems},
	author = {Benetos, E. and Dixon, S. and Giannoulis, D. and Kirchhoff, H. and Klapuri, A.},
	month = jul,
	year = {2013},
	pages = {1--28},
	file = {Full Text PDF:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/K23EC93M/Benetos et al. - 2013 - Automatic music transcription challenges and futu.pdf:application/pdf;Snapshot:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/6ZZGF3H7/2524.html:text/html}
}

@article{_automatic_????,
	title = {Automatic {Transcription} of {Melody}, {Bass} {Line}, and {Chords} in {Polyphonic} {Music}},
	url = {https://www.researchgate.net/publication/220386654_Automatic_Transcription_of_Melody_Bass_Line_and_Chords_in_Polyphonic_Music},
	doi = {http://dx.doi.org/10.1162/comj.2008.32.3.72},
	abstract = {Automatic Transcription of Melody, Bass Line, and Chords in Polyphonic Music on ResearchGate, the professional network for scientists.},
	urldate = {2017-02-28},
	journal = {ResearchGate},
	file = {Snapshot:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/53VSFP59/220386654_Automatic_Transcription_of_Melody_Bass_Line_and_Chords_in_Polyphonic_Music.html:text/html}
}

@inproceedings{benetos_automatic_2014,
	title = {Automatic transcription of pitched and unpitched sounds from polyphonic music},
	doi = {10.1109/ICASSP.2014.6854172},
	abstract = {Automatic transcription of polyphonic music has been an active research field for several years and is considered by many to be a key enabling technology in music signal processing. However, current transcription approaches either focus on detecting pitched sounds (from pitched musical instruments) or on detecting unpitched sounds (from drum kits). In this paper, we propose a method that jointly transcribes pitched and unpitched sounds from polyphonic music recordings. The proposed model extends the probabilistic latent component analysis algorithm and supports the detection of pitched sounds from multiple instruments as well as the detection of un-pitched sounds from drum kit components, including bass drums, snare drums, cymbals, hi-hats, and toms. Our experiments based on polyphonic Western music containing both pitched and unpitched instruments led to very encouraging results in multi-pitch detection and drum transcription tasks.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Benetos, E. and Ewert, S. and Weyde, T.},
	month = may,
	year = {2014},
	keywords = {acoustic signal processing, audio signal processing, automatic music transcription, automatic transcription, Databases, drum transcription, Harmonic analysis, Hidden Markov models, Instruments, key enabling technology, multi-pitch detection, Multiple signal classification, music, Music signal analysis, music signal processing, pitched musical instruments, pitched sounds, polyphonic music, polyphonic music recordings, probabilistic latent component analysis algorithm, Time-frequency analysis, unpitched sounds},
	pages = {3107--3111},
	file = {IEEE Xplore Abstract Record:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/M8DX7KWN/6854172.html:text/html;IEEE Xplore Full Text PDF:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/FXTNKBI5/Benetos et al. - 2014 - Automatic transcription of pitched and unpitched s.pdf:application/pdf}
}

@misc{_classification-based_????,
	title = {Classification-{Based} {Music} {Transcription} - {PDF}},
	url = {http://docplayer.net/39879732-Classification-based-music-transcription.html},
	abstract = {Classification-Based Music Transcription Graham E. Poliner Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the Graduate School of Arts and Sciences COLUMBIA},
	urldate = {2017-02-28},
	file = {Snapshot:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/BDJFQ5EF/39879732-Classification-based-music-transcription.html:text/html}
}

@article{_harmonic_????,
	title = {Harmonic {Adaptive} {Latent} {Component} {Analysis} of {Audio} and {Application} to {Music} {Transcription} ({PDF} {Download} {Available})},
	url = {https://www.researchgate.net/publication/260697883_Harmonic_Adaptive_Latent_Component_Analysis_of_Audio_and_Application_to_Music_Transcription},
	doi = {http://dx.doi.org/10.1109/TASL.2013.2260741},
	abstract = {Official Full-Text Publication: Harmonic Adaptive Latent Component Analysis of Audio and Application to Music Transcription on ResearchGate, the professional network for scientists.},
	urldate = {2017-02-28},
	journal = {ResearchGate},
	file = {Snapshot:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/ZVT84KGG/260697883_Harmonic_Adaptive_Latent_Component_Analysis_of_Audio_and_Application_to_Music_Transcr.html:text/html}
}

@inproceedings{ming_learning_2014,
	title = {Learning optimal features for music transcription},
	doi = {10.1109/ChinaSIP.2014.6889211},
	abstract = {This paper aims to design time-frequency representation (TFR) functions for automatic music transcription. It is desirable that the decomposition of those TFR functions are suitable for notes having variation of both pitch and spectral envelop over time. The Harmonic Adaptive Latent Component Analysis (HALCA) model adopted in this paper allows considering those two kinds of variations simultaneously. We evaluate the influence of three TFR functions including IIR, FIR filter bank semigram (FBSG) and constant-Q transform semigram in automatic music transcription task, on a database of popular and polyphonic classic music. The experiment results show that the filter bank based representations are suitable for multiple-instrument recordings and a CQT-based representation turns out to provide very accurate transcription for solo-instrument recordings.},
	booktitle = {2014 {IEEE} {China} {Summit} {International} {Conference} on {Signal} and {Information} {Processing} ({ChinaSIP})},
	author = {Ming, H. and Huang, D. and Xie, L. and Li, H.},
	month = jul,
	year = {2014},
	keywords = {automatic music transcription, channel bank filters, constant-Q transform, constant-Q transform semigram, CQT-based representation, Estimation, FBSG, Feature extraction, filter bank, filter bank based representations, Finite impulse response filters, FIR filter bank semigram, FIR filters, Frequency estimation, HALCA model, harmonic adaptive latent component analysis, Harmonic analysis, Instruments, learning (artificial intelligence), logarithmic compression, multiple-instrument recordings, music, Music Transcription, optimal feature learning, pitch envelop, polyphonic classic music, Semigram features, signal representation, solo-instrument recordings, spectral envelop, Speech, Speech processing, TFR functions, Time-frequency analysis, time-frequency representation function, transforms},
	pages = {105--109},
	file = {IEEE Xplore Abstract Record:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/37UKFACS/6889211.html:text/html;IEEE Xplore Full Text PDF:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/ED9CRMZ2/Ming et al. - 2014 - Learning optimal features for music transcription.pdf:application/pdf}
}

@article{lee_multipitch_2012,
	title = {Multipitch {Estimation} of {Piano} {Music} by {Exemplar}-{Based} {Sparse} {Representation}},
	volume = {14},
	issn = {1520-9210},
	doi = {10.1109/TMM.2012.2191398},
	abstract = {Pitch, together with other midlevel music features such as rhythm and timbre, holds the promise of bridging the semantic gap between low-level features and high-level semantics for music understanding. This paper investigates the pitch estimation of a piano music signal by exemplar-based sparse representation. A note exemplar is a segment of a piano note, stored in the dictionary. We first describe how to represent a segment of the piano music signal as a linear combination of a small number of note exemplars from a large note exemplar dictionary and then show how the sparse representation problem can be solved by -regularized minimization. The proposed approach incorporates tuning factor estimation, note candidate selection, and hidden-Markov-model-based smoothing into the estimation process to improve accuracy. Unlike previous approaches, the proposed approach does not require retraining for a new piano. Instead, only a dozen notes of the new piano are needed. This feature is computationally attractive and avoids intense manual labeling. The system performance is evaluated using 70 classical music recordings of two real pianos under different recording conditions. The results show that the proposed system outperforms four state-of-the-art systems.},
	number = {3},
	journal = {IEEE Transactions on Multimedia},
	author = {Lee, C. T. and Yang, Y. H. and Chen, H. H.},
	month = jun,
	year = {2012},
	keywords = {$_{\textrm{1}}$-regularized minimization, Accuracy, acoustic signal processing, content-based retrieval, Content retrieval, Dictionaries, Estimation, exemplar-based sparse representation, exemplar dictionary, Harmonic analysis, hidden Markov model-based smoothing, Hidden Markov models, high-level semantics, Instruments, l1-regularized minimization, linear combination, low-level features, multipitch estimation, Multiple signal classification, music, musical instruments, Music Transcription, note candidate selection, piano music signal, piano note, pitch estimation, recording conditions, sparse matrices, sparse representation, system performance, tuning factor estimation},
	pages = {608--618},
	file = {IEEE Xplore Abstract Record:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/MNKFW5UC/6172242.html:text/html;IEEE Xplore Full Text PDF:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/DGAQTAXB/Lee et al. - 2012 - Multipitch Estimation of Piano Music by Exemplar-B.pdf:application/pdf}
}

@article{elvander_online_2017,
	title = {Online {Estimation} of {Multiple} {Harmonic} {Signals}},
	volume = {25},
	issn = {2329-9290},
	doi = {10.1109/TASLP.2016.2634118},
	abstract = {In this paper, we propose a time-recursive multipitch estimation algorithm using a sparse reconstruction framework, assuming that only a few pitches from a large set of candidates are active at each time instant. The proposed algorithm does not require any training data, and instead utilizes a sparse recursive least-squares formulation augmented by an adaptive penalty term specifically designed to enforce a pitch structure on the solution. The amplitudes of the active pitches are also recursively updated, allowing for a smooth and more accurate representation. When evaluated on a set of ten music pieces, the proposed method is shown to outperform other general purpose multipitch estimators in either accuracy or computational speed, although not being able to yield performance as good as the state-of-the art methods, which are being optimally tuned and specifically trained on the present instruments. However, the method is able to outperform such a technique when used without optimal tuning, or when applied to instruments not included in the training data.},
	number = {2},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Elvander, F. and Sw√§rd, J. and Jakobsson, A.},
	month = feb,
	year = {2017},
	keywords = {accurate representation, active pitches, adaptive penalty, Adaptive signal processing, Algorithm design and analysis, computational speed, Dictionaries, dictionary learning, Estimation, estimation theory, group sparsity, Harmonic analysis, Instruments, least squares approximations, multi-pitch estimation, multiple harmonic signals, online estimation, Signal processing, sparse reconstruction framework, sparse recursive least squares, sparse recursive least-squares formulation, Speech, Speech processing, time recursive multipitch estimation algorithm},
	pages = {273--284},
	file = {IEEE Xplore Abstract Record:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/CD82CGJD/7762735.html:text/html;IEEE Xplore Full Text PDF:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/R3Q82DF6/Elvander et al. - 2017 - Online Estimation of Multiple Harmonic Signals.pdf:application/pdf}
}

@inproceedings{pishdadian_transcription_2013,
	title = {On the transcription of monophonic melodies in an instance-based pitch classification scenario},
	doi = {10.1109/DSP-SPE.2013.6642594},
	abstract = {In this paper, a computationally efficient approach to transcription of monophonic melodies from a raw acoustic signal is presented. Two different instance-based pitch classification methods are proposed, the choice of which depends on the size of the available training database. In the first method, the conventional K-Nearest Neighbor algorithm is trained on a large database of piano tones and employed for monophonic pitch detection. For cases where the training database contains only one sample from each possible note, a two-step algorithm, combining semi-KNN pitch candidate selection and note sequence tracking, is suggested. It is demonstrated that in the abundance of training data, the KNN algorithm along with a proper choice of the distance measure and K, yields high performance accuracy. Furthermore, the two-step algorithm is capable of compensating for the shortage of data by incorporating prior musicological information in the transcription process.},
	booktitle = {2013 {IEEE} {Digital} {Signal} {Processing} and {Signal} {Processing} {Education} {Meeting} ({DSP}/{SPE})},
	author = {Pishdadian, F. and Nelson, J. K.},
	month = aug,
	year = {2013},
	keywords = {Accuracy, acoustic signal detection, Algorithm design and analysis, automatic music transcription, classification, Databases, distance measure, distance measurement, Feature extraction, instance-based pitch classification scenario, K-Nearest Neighbor, k-nearest neighbor algorithm training, KNN algorithm, large-piano tone database, monophonic melody transcription, monophonic pitch detection, music, musicological information, note sequence tracking, performance accuracy, piano, raw acoustic signal, semiKNN pitch candidate selection, sequence detection, signal classification, Speech processing, Testing, Training, training data, training database size, two-step algorithm, Vectors},
	pages = {222--227},
	file = {IEEE Xplore Abstract Record:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/9975IR8F/6642594.html:text/html;IEEE Xplore Full Text PDF:/Users/sunxi/Library/Application Support/Zotero/Profiles/bdtl1jin.default/zotero/storage/7HI6A6H7/Pishdadian and Nelson - 2013 - On the transcription of monophonic melodies in an .pdf:application/pdf}
}

@book{abraham_suggested_????,
	title = {Suggested {Methods} for the {Transcription} of {Exotic} {Music}},
	language = {en},
	author = {Abraham, Otto},
	note = {Google-Books-ID: z4rzJgAACAAJ}
}