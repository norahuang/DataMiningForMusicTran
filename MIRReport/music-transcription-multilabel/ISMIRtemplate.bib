% Generated by Paperpile. Check out http://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.


@INPROCEEDINGS{Holmes1994-kg,
  title     = "{WEKA}: a machine learning workbench",
  booktitle = "Intelligent Information Systems,1994. Proceedings of the 1994
               Second Australian and New Zealand Conference on",
  author    = "Holmes, G and Donkin, A and Witten, I H",
  abstract  = "WEKA is a workbench for machine learning that is intended to aid
               in the application of machine learning techniques to a variety
               of real-world problems, in particular, those arising from
               agricultural and horticultural domains. Unlike other machine
               learning projects, the emphasis is on providing a working
               environment for the domain specialist rather than the machine
               learning expert. Lessons learned include the necessity of
               providing a wealth of interactive tools for data manipulation,
               result visualization, database linkage, and cross-validation and
               comparison of rule sets, to complement the basic machine
               learning tools",
  pages     = "357--361",
  month     =  nov,
  year      =  1994,
  keywords  = "agriculture;data analysis;data visualisation;learning
               (artificial intelligence);software tools;WEKA machine learning
               workbench;agricultural domains;data manipulation;database
               linkage;domain specialist;horticultural domains;interactive
               tools;machine learning tools;real-world problems;result
               visualization;rule set comparison;rule set
               cross-validation;working environment;Application
               software;Computer science;Couplings;Data visualization;Expert
               systems;Libraries;Machine learning;Machine learning
               algorithms;User interfaces;Visual databases"
}

@ARTICLE{Platt1999-iq,
  title   = "12 fast training of support vector machines using sequential
             minimal optimization",
  author  = "Platt, John C",
  journal = "Advances in kernel methods",
  pages   = "185--208",
  year    =  1999
}

@ARTICLE{Emiya2010-ki,
  title    = "Multipitch Estimation of Piano Sounds Using a New Probabilistic
              Spectral Smoothness Principle",
  author   = "Emiya, V and Badeau, R and David, B",
  abstract = "A new method for the estimation of multiple concurrent pitches in
              piano recordings is presented. It addresses the issue of
              overlapping overtones by modeling the spectral envelope of the
              overtones of each note with a smooth autoregressive model. For
              the background noise, a moving-average model is used and the
              combination of both tends to eliminate harmonic and sub-harmonic
              erroneous pitch estimations. This leads to a complete generative
              spectral model for simultaneous piano notes, which also
              explicitly includes the typical deviation from exact harmonicity
              in a piano overtone series. The pitch set which maximizes an
              approximate likelihood is selected from among a restricted number
              of possible pitch combinations as the one. Tests have been
              conducted on a large homemade database called MAPS, composed of
              piano recordings from a real upright piano and from high-quality
              samples.",
  journal  = "IEEE Trans. Audio Speech Lang. Processing",
  volume   =  18,
  number   =  6,
  pages    = "1643--1654",
  month    =  aug,
  year     =  2010,
  keywords = "acoustic signal processing;autoregressive processes;musical
              instruments;probability;smoothing methods;spectral
              analysis;MAPS;homemade database;moving-average model;multipitch
              estimation;overlapping overtones;piano overtone series;piano
              recordings;piano sounds;probabilistic spectral smoothness
              principle;smooth autoregressive model;spectral envelope
              modeling;Audio recording;Background noise;Databases;Image
              analysis;Instruments;Pattern matching;Signal analysis;Signal
              processing;Testing;Acoustic signal analysis;audio
              processing;multipitch estimation (MPE);piano;spectral
              smoothness;transcription"
}

@INPROCEEDINGS{Anan2012-up,
  title     = "Polyphonic Music Classification on Symbolic Data Using
               Dissimilarity Functions",
  booktitle = "{ISMIR}",
  author    = "Anan, Yoko and Hatano, Kohei and Bannai, Hideo and Takeda,
               Masayuki and Satoh, Ken",
  pages     = "229--234",
  year      =  2012
}

@ARTICLE{Read2012-sh,
  title   = "{MEKA}: a multi-label extension to {WEKA}",
  author  = "Read, Jesse and Reutemann, Peter",
  journal = "URL http://meka. sourceforge. net",
  year    =  2012
}

@ARTICLE{Tzanetakis2000-xp,
  title   = "Marsyas: A framework for audio analysis",
  author  = "Tzanetakis, George and Cook, Perry",
  journal = "Organised sound",
  volume  =  4,
  number  =  3,
  pages   = "169--175",
  year    =  2000
}


@INCOLLECTION{noauthor_2005-hn,
  title     = "Spectral Centroid",
  booktitle = "Van Nostrand's Scientific Encyclopedia",
  publisher = "John Wiley \& Sons, Inc.",
  year      =  2005,
  keywords  = "spectral centroid"
}

@ARTICLE{Lee2012-dd,
  title    = "Multipitch Estimation of Piano Music by {Exemplar-Based} Sparse
              Representation",
  author   = "Lee, C T and Yang, Y H and Chen, H H",
  abstract = "Pitch, together with other midlevel music features such as rhythm
              and timbre, holds the promise of bridging the semantic gap
              between low-level features and high-level semantics for music
              understanding. This paper investigates the pitch estimation of a
              piano music signal by exemplar-based sparse representation. A
              note exemplar is a segment of a piano note, stored in the
              dictionary. We first describe how to represent a segment of the
              piano music signal as a linear combination of a small number of
              note exemplars from a large note exemplar dictionary and then
              show how the sparse representation problem can be solved by
              -regularized minimization. The proposed approach incorporates
              tuning factor estimation, note candidate selection, and
              hidden-Markov-model-based smoothing into the estimation process
              to improve accuracy. Unlike previous approaches, the proposed
              approach does not require retraining for a new piano. Instead,
              only a dozen notes of the new piano are needed. This feature is
              computationally attractive and avoids intense manual labeling.
              The system performance is evaluated using 70 classical music
              recordings of two real pianos under different recording
              conditions. The results show that the proposed system outperforms
              four state-of-the-art systems.",
  journal  = "IEEE Trans. Multimedia",
  volume   =  14,
  number   =  3,
  pages    = "608--618",
  month    =  jun,
  year     =  2012,
  keywords = "acoustic signal processing;content-based retrieval;hidden Markov
              models;music;musical instruments;sparse matrices;exemplar
              dictionary;exemplar-based sparse representation;hidden Markov
              model-based smoothing;high-level
              semantics;l<sub>1</sub>-regularized minimization;linear
              combination;low-level features;multipitch estimation;note
              candidate selection;piano music signal;piano note;recording
              conditions;system performance;tuning factor
              estimation;Accuracy;Dictionaries;Estimation;Harmonic
              analysis;Instruments;Multiple signal
              classification;Music;<formula formulatype=``inline''><tex
              Notation=``TeX''>$l_1$</tex></formula>-regularized
              minimization;Content retrieval;music transcription;pitch
              estimation;sparse representation"
}

@phdthesis{hall1999correlation,
  title={Correlation-based feature selection for machine learning},
  author={Hall, Mark A},
  year={1999},
  school={The University of Waikato}
}

@article{hall2003benchmarking,
  title={Benchmarking attribute selection techniques for discrete class data mining},
  author={Hall, Mark A and Holmes, Geoffrey},
  journal={IEEE Transactions on Knowledge and Data engineering},
  volume={15},
  number={6},
  pages={1437--1447},
  year={2003},
  publisher={IEEE}
}

@INPROCEEDINGS{Ming2014-cj,
  title     = "Learning optimal features for music transcription",
  booktitle = "2014 {IEEE} China Summit International Conference on Signal and
               Information Processing ({ChinaSIP})",
  author    = "Ming, H and Huang, D and Xie, L and Li, H",
  abstract  = "This paper aims to design time-frequency representation (TFR)
               functions for automatic music transcription. It is desirable
               that the decomposition of those TFR functions are suitable for
               notes having variation of both pitch and spectral envelop over
               time. The Harmonic Adaptive Latent Component Analysis (HALCA)
               model adopted in this paper allows considering those two kinds
               of variations simultaneously. We evaluate the influence of three
               TFR functions including IIR, FIR filter bank semigram (FBSG) and
               constant-Q transform semigram in automatic music transcription
               task, on a database of popular and polyphonic classic music. The
               experiment results show that the filter bank based
               representations are suitable for multiple-instrument recordings
               and a CQT-based representation turns out to provide very
               accurate transcription for solo-instrument recordings.",
  pages     = "105--109",
  month     =  jul,
  year      =  2014,
  keywords  = "FIR filters;channel bank filters;harmonic analysis;learning
               (artificial intelligence);music;signal
               representation;time-frequency analysis;transforms;CQT-based
               representation;FBSG;FIR filter bank semigram;HALCA model;TFR
               functions;automatic music transcription;constant-Q transform
               semigram;filter bank based representations;harmonic adaptive
               latent component analysis;multiple-instrument recordings;optimal
               feature learning;pitch envelop;polyphonic classic
               music;solo-instrument recordings;spectral envelop;time-frequency
               representation function;Estimation;Feature extraction;Finite
               impulse response filters;Frequency
               estimation;Instruments;Speech;Speech processing;Semigram
               features;constant-Q transform;filter bank;logarithmic
               compression;music transcription"
}

@ARTICLE{Sigtia2016-sz,
  title     = "An End-to-end Neural Network for Polyphonic Piano Music
               Transcription",
  author    = "Sigtia, Siddharth and Benetos, Emmanouil and Dixon, Simon",
  journal   = "IEEE/ACM Trans. Audio, Speech and Lang. Proc.",
  publisher = "IEEE Press",
  volume    =  24,
  number    =  5,
  pages     = "927--939",
  month     =  may,
  year      =  2016,
  address   = "Piscataway, NJ, USA",
  keywords  = "automatic music transcription, deep learning, music language
               models, recurrent neural networks"
}

@ARTICLE{Aha1991-ir,
  title     = "Instance-based learning algorithms",
  author    = "Aha, David W and Kibler, Dennis and Albert, Marc K",
  abstract  = "Storing and using specific instances improves the performance of
               several supervised learning algorithms. These include algorithms
               that learn decision trees, classification rules, and distributed
               networks. However, no investigation has analyzed algorithms that
               use only specific instances to solve incremental learning tasks.
               In this paper, we describe a framework and methodology, called
               instance-based learning, that generates classification
               predictions using only specific instances. Instance-based
               learning algorithms do not maintain a set of abstractions
               derived from specific instances. This approach extends the
               nearest neighbor algorithm, which has large storage
               requirements. We describe how storage requirements can be
               significantly reduced with, at most, minor sacrifices in
               learning rate and classification accuracy. While the
               storage-reducing algorithm performs well on several real-world
               databases, its performance degrades rapidly with the level of
               attribute noise in training instances. Therefore, we extended it
               with a significance test to distinguish noisy instances. This
               extended algorithm's performance degrades gracefully with
               increasing noise levels and compares favorably with a
               noise-tolerant decision tree algorithm.",
  journal   = "Mach. Learn.",
  publisher = "Kluwer Academic Publishers",
  volume    =  6,
  number    =  1,
  pages     = "37--66",
  month     =  "1~" # jan,
  year      =  1991,
  language  = "en"
}

@INPROCEEDINGS{Poliner2005-ow,
  title     = "A Classification Approach to Melody Transcription",
  booktitle = "{ISMIR}",
  author    = "Poliner, Graham E and Ellis, Daniel P W",
  volume    =  2005,
  pages     = "6th",
  year      =  2005
}

@ARTICLE{Benetos2013-io,
  title     = "Automatic music transcription: challenges and future directions",
  author    = "Benetos, Emmanouil and Dixon, Simon and Giannoulis, Dimitrios
               and Kirchhoff, Holger and Klapuri, Anssi",
  abstract  = "Automatic music transcription is considered by many to be a key
               enabling technology in music signal processing. However, the
               performance of transcription systems is still significantly
               below that of a human expert, and accuracies reported in recent
               years seem to have reached a limit, although the field is still
               very active. In this paper we analyse limitations of current
               methods and identify promising directions for future research.
               Current transcription methods use general purpose models which
               are unable to capture the rich diversity found in music signals.
               One way to overcome the limited performance of transcription
               systems is to tailor algorithms to specific use-cases.
               Semi-automatic approaches are another way of achieving a more
               reliable transcription. Also, the wealth of musical scores and
               corresponding audio data now available are a rich potential
               source of training data, via forced alignment of audio to
               scores, but large scale utilisation of such data has yet to be
               attempted. Other promising approaches include the integration of
               information from multiple algorithms and different musical
               aspects.",
  journal   = "J. Intell. Inf. Syst.",
  publisher = "Springer US",
  volume    =  41,
  number    =  3,
  pages     = "407--434",
  month     =  "1~" # dec,
  year      =  2013,
  language  = "en"
}

@ARTICLE{Dugan2015-fn,
  title       = "Machine Learning Techniques for Prediction of Early Childhood
                 Obesity",
  author      = "Dugan, T M and Mukhopadhyay, S and Carroll, A and Downs, S",
  affiliation = "Indiana University , Children's Health Services Research,
                 Indianapolis, IN, United States ; Indiana University Purdue
                 University Indianapolis , Computer Science, Indianapolis, IN,
                 United States. Indiana University Purdue University
                 Indianapolis , Computer Science, Indianapolis, IN, United
                 States. Indiana University , Children's Health Services
                 Research, Indianapolis, IN, United States. Indiana University
                 , Children's Health Services Research, Indianapolis, IN,
                 United States.",
  abstract    = "OBJECTIVES: This paper aims to predict childhood obesity after
                 age two, using only data collected prior to the second
                 birthday by a clinical decision support system called CHICA.
                 METHODS: Analyses of six different machine learning methods:
                 RandomTree, RandomForest, J48, ID3, Na{\"\i}ve Bayes, and
                 Bayes trained on CHICA data show that an accurate, sensitive
                 model can be created. RESULTS: Of the methods analyzed, the
                 ID3 model trained on the CHICA dataset proved the best overall
                 performance with accuracy of 85\% and sensitivity of 89\%.
                 Additionally, the ID3 model had a positive predictive value of
                 84\% and a negative predictive value of 88\%. The structure of
                 the tree also gives insight into the strongest predictors of
                 future obesity in children. Many of the strongest predictors
                 seen in the ID3 modeling of the CHICA dataset have been
                 independently validated in the literature as correlated with
                 obesity, thereby supporting the validity of the model.
                 CONCLUSIONS: This study demonstrated that data from a
                 production clinical decision support system can be used to
                 build an accurate machine learning model to predict obesity in
                 children after age two.",
  journal     = "Appl. Clin. Inform.",
  volume      =  6,
  number      =  3,
  pages       = "506--520",
  month       =  "12~" # aug,
  year        =  2015,
  keywords    = "Bayes theorem; Obesity; artificial intelligence; decision
                 trees; predictive analytics",
  language    = "en"
}

@INCOLLECTION{Herrera2016-ep,
  title     = "Multilabel Classification",
  booktitle = "Multilabel Classification",
  author    = "Herrera, Francisco and Charte, Francisco and Rivera, Antonio J
               and del Jesus, Mar{\'\i}a J",
  abstract  = "This book is concerned with the classification of multilabeled
               data and other tasks related to that subject. The goal of this
               chapter is to formally introduce the problem, as well as to give
               a broad overview of its main application fields and how it have
               been tackled by experts. A general introduction to the matter is
               provided in Sect. 2.1, followed by a formal definition of the
               multilabel classification problem in Sect. 2.2. Some of the main
               application fields of multilabel classification are portrayed in
               Sect. 2.3. Lastly, the approaches followed to face this duty are
               introduced in Sect. 2.4.",
  publisher = "Springer International Publishing",
  pages     = "17--31",
  year      =  2016,
  language  = "en"
}

@ARTICLE{noauthor_undated-sl,
  journal = "flux"
}

@BOOK{Ross_Quinlan2014-rg,
  title     = "C4.5: Programs for Machine Learning",
  author    = "Ross Quinlan, J",
  abstract  = "Classifier systems play a major role in machine learning and
               knowledge-based systems, and Ross Quinlan's work on ID3 and C4.5
               is widely acknowledged to have made some of the most significant
               contributions to their development. This book is a complete
               guide to the C4.5 system as implemented in C for the UNIX
               environment. It contains a comprehensive guide to the system's
               use , the source code (about 8,800 lines), and implementation
               notes. C4.5 starts with large sets of cases belonging to known
               classes. The cases, described by any mixture of nominal and
               numeric properties, are scrutinized for patterns that allow the
               classes to be reliably discriminated. These patterns are then
               expressed as models, in the form of decision trees or sets of
               if-then rules, that can be used to classify new cases, with
               emphasis on making the models understandable as well as
               accurate. The system has been applied successfully to tasks
               involving tens of thousands of cases described by hundreds of
               properties. The book starts from simple core learning methods
               and shows how they can be elaborated and extended to deal with
               typical problems such as missing data and over hitting.
               Advantages and disadvantages of the C4.5 approach are discussed
               and illustrated with several case studies. This book should be
               of interest to developers of classification-based intelligent
               systems and to students in machine learning and expert systems
               courses.",
  publisher = "Elsevier",
  month     =  "28~" # jun,
  year      =  2014,
  language  = "en"
}

@INPROCEEDINGS{Duan2015-nt,
  title       = "Automatic music transcription",
  author      = "Duan, Zhiyao and Benetos, Emmanouil",
  institution = "ISMIR",
  year        =  2015
}

@INCOLLECTION{Bundy1984-fo,
  title     = "{Zero-Crossings}",
  booktitle = "Catalogue of Artificial Intelligence Tools",
  author    = "Bundy, Alan and Wallen, Lincoln",
  editor    = "Bundy, Alan and Wallen, Lincoln",
  abstract  = "A point at which a mathematical function changes its sign, i.e.
               passes through zero. Technically a zero-crossing is defined as
               the intersection of the zero plane (z=0) with a surface
               (z=f(x,y)). Convolving a grey-level image with a difference of
               gaussians operator and then finding zero crossings in the output
               is one way of looking for edge points. See edge detection .",
  publisher = "Springer Berlin Heidelberg",
  pages     = "135--136",
  series    = "Symbolic Computation",
  year      =  1984,
  language  = "en"
}
